{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d50a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "import paramiko\n",
    "from datetime import date\n",
    "\n",
    "# Configure basic loggig\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define constants and file paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, 'data')\n",
    "ENV_FILE_PATH = os.path.join(PROJECT_ROOT, '.env')\n",
    "ANALYSIS_TRACKER_FILENAME = 'log_analysis_tracker.xlsx'\n",
    "ANALYSIS_TRACKER_PATH = os.path.join(DATA_DIR, ANALYSIS_TRACKER_FILENAME)\n",
    "\n",
    "\n",
    "# Column name in Excel containing remote log directory paths\n",
    "LOG_PATH_COLUMN = 'remote_log_directory'\n",
    "\n",
    "# Define SFTP Port for Docker container connection\n",
    "SFTP_PORT = 2222\n",
    "\n",
    "# Base dir for local logs\n",
    "LOCAL_LOG_STORAGE_BASE = os.path.join(DATA_DIR, 'downloaded_logs')\n",
    "\n",
    "# Keywords to search for in logs (Make these match your sample logs)\n",
    "SUCCESS_KEYWORD = 'Execution Return Code: 0'\n",
    "FAILURE_KEYWORD = '*** Failure'\n",
    "ERROR_KEYWORD = '*** Error:'\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def get_analysis_tracker(filename: str, required_col: str) -> pd.DataFrame | None:\n",
    "    \"\"\"Loads the analysis tracker Excel file into a pandas DataFrame.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        logging.error(f\"Tracker file not found: '{filename}'. Please create it.\")\n",
    "        return None\n",
    "\n",
    "    logging.info(f\"Loading tracker file: '{filename}'\")\n",
    "    try:\n",
    "        df = pd.read_excel(filename, header=0)\n",
    "        logging.info(f\"Successfully loaded tracker with shape: {df.shape}\")\n",
    "        if required_col not in df.columns:\n",
    "            logging.error(f\"Tracker file '{filename}' is missing the required column: '{required_col}'\")\n",
    "            return None\n",
    "        logging.info(f\"Required column '{required_col}' found in tracker.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to read tracker file '{filename}': {e}\")\n",
    "        return None\n",
    "\n",
    "def get_current_date_string() -> str:\n",
    "    \"\"\"Returns today's date as a string in 'YYYYMMDD' format.\"\"\"\n",
    "    return date.today().strftime('%Y%m%d')\n",
    "\n",
    "def get_log_download_directory(base_dir: str, date_string: str) -> str:\n",
    "    \"\"\"Constructs the path to the directory holding logs for a specific date.\"\"\"\n",
    "    return os.path.join(base_dir, f\"{date_string}_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422c18a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 16:35:22,657 - INFO - Starting analysis of logs in directory: /Users/benkaan/Desktop/projects/remote-log-analysis-automation/data/downloaded_logs/20250501_logs\n",
      "2025-05-01 16:35:22,657 - INFO - Found 12 log files to analyze.\n",
      "2025-05-01 16:35:22,658 - WARNING - Found error keyword in job_conversion_rate-20250501_083000.log: *** Error: Division by zero encountered in conversion calculation.\n",
      "2025-05-01 16:35:22,658 - INFO - Analysis result for 'job_conversion_rate-20250501_083000.log': error\n",
      "2025-05-01 16:35:22,659 - WARNING - Found error keyword in job_payment_proc-20250501_083000.log: *** Error: Unable to update payment status. Database timeout.\n",
      "2025-05-01 16:35:22,659 - INFO - Analysis result for 'job_payment_proc-20250501_083000.log': error\n",
      "2025-05-01 16:35:22,660 - INFO - Analysis result for 'job_report_monthly-20250501_083000.log': success\n",
      "2025-05-01 16:35:22,661 - INFO - Analysis result for 'job_tax_calc-20250501_083000.log': success\n",
      "2025-05-01 16:35:22,662 - INFO - Analysis result for 'job_email_blast-20250501_083000.log': success\n",
      "2025-05-01 16:35:22,663 - INFO - Analysis result for 'job_update_crm-20250501_083000.log': success\n",
      "2025-05-01 16:35:22,663 - INFO - Analysis result for 'job_web_traffic-20250501_083000.log': success\n",
      "2025-05-01 16:35:22,664 - INFO - Analysis result for 'job_report_daily-20250501_083000.log': success\n",
      "2025-05-01 16:35:22,664 - INFO - Analysis result for 'job_roi_report-20250501_083000.log': success\n",
      "2025-05-01 16:35:22,665 - INFO - Analysis result for 'job_invoice_gen-20250501_083000.log': success\n",
      "2025-05-01 16:35:22,665 - WARNING - Found error keyword in job_report_weekly-20250501_083000.log: *** Error: Data source unavailable. Aborting report generation.\n",
      "2025-05-01 16:35:22,665 - INFO - Analysis result for 'job_report_weekly-20250501_083000.log': error\n",
      "2025-05-01 16:35:22,666 - WARNING - Found error keyword in job_segment_users-20250501_083000.log: *** Error: No eligible users found for segmentation.\n",
      "2025-05-01 16:35:22,666 - INFO - Analysis result for 'job_segment_users-20250501_083000.log': error\n",
      "2025-05-01 16:35:22,666 - INFO - Log analysis finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analysis Results ---\n",
      "Analysis Summary for logs in '/Users/benkaan/Desktop/projects/remote-log-analysis-automation/data/downloaded_logs/20250501_logs':\n",
      "  - Success: 8\n",
      "  - Failure: 0\n",
      "  - Error:   4\n",
      "  - Unknown: 0\n",
      "\n",
      "Individual File Status:\n",
      "  - job_conversion_rate-20250501_083000.log: error\n",
      "  - job_email_blast-20250501_083000.log: success\n",
      "  - job_invoice_gen-20250501_083000.log: success\n",
      "  - job_payment_proc-20250501_083000.log: error\n",
      "  - job_report_daily-20250501_083000.log: success\n",
      "  - job_report_monthly-20250501_083000.log: success\n",
      "  - job_report_weekly-20250501_083000.log: error\n",
      "  - job_roi_report-20250501_083000.log: success\n",
      "  - job_segment_users-20250501_083000.log: error\n",
      "  - job_tax_calc-20250501_083000.log: success\n",
      "  - job_update_crm-20250501_083000.log: success\n",
      "  - job_web_traffic-20250501_083000.log: success\n"
     ]
    }
   ],
   "source": [
    "def analyze_downloaded_logs(local_log_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyzes the downloaded log files found in the specified local directory.\n",
    "\n",
    "    Args:\n",
    "        local_log_dir (str): The local directory containing downloaded logs for a specific date.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping log filenames to their determined status\n",
    "              ('success', 'failure', 'error', 'unknown', 'parse_error', 'not_found').\n",
    "              Returns an empty dict if the directory doesn't exist.\n",
    "    \"\"\"\n",
    "    log_analysis_results = {}\n",
    "    logging.info(f\"Starting analysis of logs in directory: {local_log_dir}\")\n",
    "\n",
    "    if not os.path.isdir(local_log_dir):\n",
    "        logging.error(f\"Local log directory not found: {local_log_dir}. Cannot analyze.\")\n",
    "        return {'error': 'directory_not_found'} # Indicate directory missing\n",
    "\n",
    "    local_log_files = os.listdir(local_log_dir)\n",
    "    if not local_log_files:\n",
    "        logging.warning(f\"No log files found in local directory: {local_log_dir}\")\n",
    "        return {} # Return empty if no files to analyze\n",
    "\n",
    "    logging.info(f\"Found {len(local_log_files)} log files to analyze.\")\n",
    "\n",
    "    for log_filename in local_log_files:\n",
    "        local_log_path = os.path.join(local_log_dir, log_filename)\n",
    "        analysis_status = 'unknown' # Default status\n",
    "\n",
    "        try:\n",
    "            logging.debug(f\"Analyzing file: {log_filename}\")\n",
    "            with open(local_log_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.readlines()\n",
    "                log_found_keyword = False\n",
    "                # Search from end of file backwards for efficiency\n",
    "                for line in reversed(content):\n",
    "                    if SUCCESS_KEYWORD in line:\n",
    "                        analysis_status = 'success'\n",
    "                        log_found_keyword = True\n",
    "                        logging.debug(f\"Found success keyword in {log_filename}\")\n",
    "                        break\n",
    "                    elif FAILURE_KEYWORD in line:\n",
    "                        analysis_status = 'failure'\n",
    "                        log_found_keyword = True\n",
    "                        logging.warning(f\"Found failure keyword in {log_filename}: {line.strip()}\")\n",
    "                        break\n",
    "                    elif ERROR_KEYWORD in line:\n",
    "                        analysis_status = 'error'\n",
    "                        log_found_keyword = True\n",
    "                        logging.warning(f\"Found error keyword in {log_filename}: {line.strip()}\")\n",
    "                        break\n",
    "\n",
    "                # If loop completes without finding keywords, status remains 'unknown'\n",
    "                if not log_found_keyword:\n",
    "                     logging.info(f\"No specific keywords found in {log_filename}, status set to 'unknown'.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "             logging.error(f\"Log file vanished during analysis?: {local_log_path}\")\n",
    "             analysis_status = 'not_found' # Should not happen if listed initially\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading or parsing log file {log_filename}: {e}\")\n",
    "            analysis_status = 'parse_error'\n",
    "\n",
    "        log_analysis_results[log_filename] = analysis_status\n",
    "        logging.info(f\"Analysis result for '{log_filename}': {analysis_status}\")\n",
    "\n",
    "    logging.info(\"Log analysis finished.\")\n",
    "    return log_analysis_results\n",
    "\n",
    "# --- Execute Analysis ---\n",
    "\n",
    "# Determine local log directory\n",
    "today_date_str = get_current_date_string()\n",
    "local_log_dir_to_analyze = get_log_download_directory(LOCAL_LOG_STORAGE_BASE, today_date_str)\n",
    "\n",
    "# Run the analysis\n",
    "analysis_results = analyze_downloaded_logs(local_log_dir_to_analyze)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n--- Analysis Results ---\")\n",
    "if analysis_results:\n",
    "    if 'error' in analysis_results and analysis_results['error'] == 'directory_not_found':\n",
    "         print(f\"Error: Local log directory not found at '{local_log_dir_to_analyze}'\")\n",
    "    else:\n",
    "        # Pretty print the results\n",
    "        success_count = sum(1 for status in analysis_results.values() if status == 'success')\n",
    "        failure_count = sum(1 for status in analysis_results.values() if status == 'failure')\n",
    "        error_count = sum(1 for status in analysis_results.values() if status == 'error')\n",
    "        unknown_count = sum(1 for status in analysis_results.values() if status == 'unknown')\n",
    "        other_count = len(analysis_results) - (success_count + failure_count + error_count + unknown_count)\n",
    "\n",
    "        print(f\"Analysis Summary for logs in '{local_log_dir_to_analyze}':\")\n",
    "        print(f\"  - Success: {success_count}\")\n",
    "        print(f\"  - Failure: {failure_count}\")\n",
    "        print(f\"  - Error:   {error_count}\")\n",
    "        print(f\"  - Unknown: {unknown_count}\")\n",
    "        if other_count > 0:\n",
    "             print(f\"  - Other (parse_error/not_found): {other_count}\")\n",
    "        print(\"\\nIndividual File Status:\")\n",
    "        for filename, status in sorted(analysis_results.items()):\n",
    "            print(f\"  - {filename}: {status}\")\n",
    "else:\n",
    "     print(f\"No logs were analyzed from '{local_log_dir_to_analyze}'. Directory might be empty or non-existent.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
